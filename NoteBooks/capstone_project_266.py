# -*- coding: utf-8 -*-
"""Capstone Project - 266.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UNVkWT1Nzgifl8K68gYqHY6Uk39aJwWZ

# Capstone Project - Januka Dharmapriya (266)

---
"""

import numpy as np 
import pandas as pd 
import os

from sklearn import preprocessing
from scipy.stats import pearsonr

# machine learning  - supervised
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.metrics import accuracy_score

"""# Loading the Training and Testing datasets

- Read two seperate work sheets in the same Excel file using pandas.
"""

train_df = pd.read_csv('https://raw.githubusercontent.com/JanukaD/Capstone-Project/main/datasets/1/train.csv')
test_df = pd.read_csv('https://raw.githubusercontent.com/JanukaD/Capstone-Project/main/datasets/1/test.csv')

"""## - Describing the Training dataset

- First five rows of the training dataset.
"""

train_df.head()

"""- Check the columns that contains null values in the training dataset."""

train_df.info()

"""- Count of the null values in each column in the training dataset."""

train_df.isnull().sum()

"""- Describing the Training dataset"""

train_df.describe()

"""## - Describing the Testing dataset

- First five rows of the testing dataset.
"""

test_df.head()

"""- Check the columns that contains null values in the testing dataset."""

test_df.info()

"""- Count of the null values in each column in the testing dataset."""

test_df.isnull().sum()

"""- Describing the Testing dataset"""

test_df.describe()

"""# Visualization of the datasets"""

import matplotlib.pyplot as plt
import seaborn as sns

"""- Class distribution of the Training dataset"""

graph = sns.countplot(data = train_df, x = "Class", label = "Count", palette="Greens")
plt.title('Patients Count - Training Dataset')
plt.xlabel('Patients status')
plt.ylabel('Value')

i=0
for p in graph.patches:
    height = p.get_height()
    graph.text(p.get_x()+p.get_width()/2., height + 0.1,
        train_df['Class'].value_counts()[i],ha="center")
    i += 1

"""- Class distribution of the Test dataset"""

graph = sns.countplot(data = test_df, x = "Class", label = "Count", palette="Purples")
plt.title('Patients Count - Testing Dataset')
plt.xlabel('Patients status')
plt.ylabel('Value')

i=0
for p in graph.patches:
    height = p.get_height()
    graph.text(p.get_x()+p.get_width()/2., height + 0.1,
        test_df['Class'].value_counts()[i],ha="center")
    i += 1

"""# Data pre-processing

- Convert categorical variables (Gender & Class) to the dummy variables - Training dataset
"""

train_df_dummy = pd.get_dummies(train_df, columns=["Gender","Class"], drop_first=True)
print(train_df_dummy.head(6))

"""- Convert categorical variables (Gender & class) to the dummy variables - Testing dataset"""

test_df_dummy = pd.get_dummies(test_df, columns=["Gender","Class"], drop_first=True)
print(test_df_dummy.head(6))

"""- Fill missing values in column with mean - Training dataset"""

from sklearn.impute import SimpleImputer

imp=SimpleImputer(missing_values=np.NaN, strategy = 'mean')

train_df_imputed = pd.DataFrame(imp.fit_transform(train_df_dummy))
train_df_imputed.columns=train_df_dummy.columns
train_df_imputed.index=train_df_dummy.index

train_df_imputed.info()

train_df_imputed.isnull().sum()

"""- Fill missing values in column with mean - Testing dataset"""

test_df_imputed = pd.DataFrame(imp.fit_transform(test_df_dummy))
test_df_imputed.columns=test_df_dummy.columns
test_df_imputed.index=test_df_dummy.index

test_df_imputed.info()

test_df_imputed.isnull().sum()

"""# Feature Selection for training process

- Correlations in the training dataset
"""

train_df_imputed.corr()

correlations = train_df_imputed.corr()
plt.figure(figsize=(14,14))
g = sns.heatmap(correlations,cbar = True, square = True, annot=True, fmt= '.2f', annot_kws={'size': 10})

g = sns.PairGrid(train_df_imputed, hue = "Class_Yes", vars=['Age','TB','DB','ALK', 'SGPT', 'SGOT', 'TP', 'ALB',
                                                                'AG_Ratio', 'Gender_Male'])
g.map(plt.scatter)
plt.show()

"""- Getting "ANOVA F" measures"""

from sklearn.feature_selection import SelectKBest,f_classif

fvalue_selector = SelectKBest(score_func=f_classif, k="all")

X = train_df_imputed[train_df_imputed.columns.drop("Class_Yes")]
y = (train_df_imputed["Class_Yes"])

fvalue_selector.fit(X, y)
names = X.columns.values[fvalue_selector.get_support()]
scores = fvalue_selector.scores_[fvalue_selector.get_support()]
names_scores = list(zip(names, scores))
ns_df = pd.DataFrame(data = names_scores, columns= ['Feature_name','F_Score'])
ns_df_sorted = ns_df.sort_values(['F_Score','Feature_name'], ascending = [False, True])
print(ns_df_sorted)

"""# Building the Model"""

import tensorflow as tf

train_df_labels = np.array(train_df_imputed.pop("Class_Yes"))
test_df_labels = np.array(test_df_imputed.pop("Class_Yes"))

"""- Training the selected features (except the Gender)"""

selected_feature_columns = ['Age', 'Gender_Male','TB','DB','ALK', 'SGPT', 'SGOT', 'ALB','AG_Ratio']

train_features = np.array(train_df_imputed[selected_feature_columns])
test_features = np.array(test_df_imputed[selected_feature_columns])

"""- Standardizing the selected features using skleran"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
train_features = scaler.fit_transform(train_features)
test_features = scaler.transform(test_features)

train_features = np.clip(train_features, -3, 3)
test_features = np.clip(test_features, -3, 3)

"""- Creating a Keras model (Sequential model)"""

from tensorflow import keras
from tensorflow.keras import layers

maxnorm = tf.keras.constraints.max_norm

model = keras.Sequential(
    [
        layers.Dense(128, activation="relu", input_shape=(9,), kernel_constraint=maxnorm(3)), #input layer
        layers.Dropout(0.5),
        
        layers.Dense(128, activation="relu", kernel_constraint=maxnorm(3)),
        layers.Dropout(0.5),
        
        layers.Dense(32, kernel_constraint=maxnorm(3)),
        layers.Dropout(0.2),
        
        layers.Dense(1, activation='sigmoid'), #output layer
    ]
)

#Model compilation
model.compile(optimizer='Nadam',
                 loss="binary_crossentropy",
                 metrics=[tf.keras.metrics.TruePositives(name='truepositives'),
                          tf.keras.metrics.FalsePositives(name='falsepositives'),
                          tf.keras.metrics.TrueNegatives(name='truenegatives'),
                          tf.keras.metrics.FalseNegatives(name='falsenegatives'),
                          tf.keras.metrics.BinaryAccuracy(name='accuracy'),
                          tf.keras.metrics.Precision(name='precision'),
                          tf.keras.metrics.Recall(name='recall'),
                          tf.keras.metrics.AUC(name='auc')])

model.summary()

model.get_config()

"""# Training the model

- Training the build model using dataset
"""

model_trained = model.fit(
    train_features,
    train_df_labels,
    batch_size=320,
    epochs=1000,
    verbose=1,)

"""- Evaluate the built model"""

results = model.evaluate(train_features, train_df_labels, batch_size=32, verbose=0)

for x in range(len(results)):
    print(f"{model.metrics_names[x]}: {results[x]}")

"""- summarize history for Accuracy & Loss"""

# summarize history for accuracy
plt.figure(figsize=(10,10))
plt.plot(model_trained.history['accuracy'])
plt.title('Model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# summarize history for loss
plt.figure(figsize=(10,10))
plt.plot(model_trained.history['loss'])
plt.title('Model loss')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')

"""# Evaluating the model"""

train_predictions_baseline = model.predict(train_features, batch_size=32)
test_predictions_baseline = model.predict(test_features, batch_size=32)

"""- Confusion Matrix"""

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(test_df_labels, test_predictions_baseline >0.5)
plt.figure(figsize=(12,12))
sns.heatmap(cm, annot=True, fmt="d",xticklabels=True, yticklabels=True,)

plt.title('Confusion matrix')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

print('Correctly identified negative patients (True Negatives): ', cm[0][0])
print('Incorrectly identified negative patients (False Positives): ', cm[0][1])
print('Incorrectly identified positive patients:(False Negatives): ', cm[1][0])
print('Correctly identified positive patients (True Positives): ', cm[1][1])
print('Total Positive patients: ', np.sum(cm[1]))
print('Total Negative Patients: ', np.sum(cm[0]))